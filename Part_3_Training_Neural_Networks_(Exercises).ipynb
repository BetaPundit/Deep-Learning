{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 3 - Training Neural Networks (Exercises).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityaas26/Deep-Learning/blob/master/Part_3_Training_Neural_Networks_(Exercises).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbeSCHEBGtgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper.py\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def test_network(net, trainloader):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # Create Variables for the inputs and targets\n",
        "    inputs = Variable(images)\n",
        "    targets = Variable(images)\n",
        "\n",
        "    # Clear the gradients from all Variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass, then backward pass, then update weights\n",
        "    output = net.forward(inputs)\n",
        "    loss = criterion(output, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def view_recon(img, recon):\n",
        "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
        "        reconstruction also a PyTorch Tensor\n",
        "    '''\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
        "    axes[0].imshow(img.numpy().squeeze())\n",
        "    axes[1].imshow(recon.data.numpy().squeeze())\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box-forced')\n",
        "\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCKC0lcCbMEO",
        "colab_type": "code",
        "outputId": "fe1e6172-6604-4fc4-8a48-1a2d8d3046f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, ), (0.5, )),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 20595397.28it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 327846.02it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 5313583.97it/s]                           \n",
            "8192it [00:00, 129559.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqj2Qi-tFNwj",
        "colab_type": "code",
        "outputId": "e7f51a3d-89d7-489c-e14a-4811e0966f4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get our data\n",
        "dataIter = iter(trainloader)\n",
        "images, labels = dataIter.next()\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2930, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4pURmpDFtPZ",
        "colab_type": "code",
        "outputId": "13d91a70-1615-4380-f56d-f14a791ebfb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "Exercise: Build a model that returns the log-softmax as the output and calculate \n",
        "the loss using the negative log likelihood loss. Note that for nn.LogSoftmax and \n",
        "F.log_softmax you'll need to set the dim keyword argument appropriately. dim=0 \n",
        "calculates softmax across the rows, so each column sums to 1, while dim=1 calculates \n",
        "across the columns so each row sums to 1. Think about what you want the output to \n",
        "be and choose dim appropriately.\n",
        "\n",
        "'''\n",
        "\n",
        "# TODO: Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                     nn.ReLU(),\n",
        "                     nn.Linear(128, 64),\n",
        "                     nn.ReLU(),\n",
        "                     nn.Linear(64, 10),\n",
        "                     nn.LogSoftmax(dim = 1))\n",
        "\n",
        "# TODO: Define the loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "### Run this to check your work\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3152, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zutNFNdK2tqt",
        "colab_type": "code",
        "outputId": "5f118e33-792d-477e-89de-b7d4678fc091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Training the network\n",
        "\n",
        "from torch import optim\n",
        "\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        \n",
        "        # Clear the gradients, do this because gradients are accumulated\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "        # TODO: Training pass\n",
        "        output = model.forward(images)       \n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 1.895042269341727\n",
            "Training loss: 0.838020187324044\n",
            "Training loss: 0.5128868535828235\n",
            "Training loss: 0.424180542656989\n",
            "Training loss: 0.383370707649539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZY2KIW6F7XL",
        "colab_type": "code",
        "outputId": "7d28a4ad-411e-4d82-eb83-a724be68bdb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import helper\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logits = model.forward(img)\n",
        "\n",
        "# Output of the network are logits, need to take softmax for probabilities\n",
        "ps = F.softmax(logits, dim=1)\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADjCAYAAADQWoDbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVgvs5r7Gnwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}